{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2020-09-17T02:57:35.930327Z","iopub.status.busy":"2020-09-17T02:57:35.92961Z","iopub.status.idle":"2020-09-17T02:58:09.467389Z","shell.execute_reply":"2020-09-17T02:58:09.467895Z"},"papermill":{"duration":33.551098,"end_time":"2020-09-17T02:58:09.468052","exception":false,"start_time":"2020-09-17T02:57:35.916954","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import copy\nimport csv\nimport gc\nimport operator\nimport os\nimport pathlib\nimport shutil\n\nimport numpy as np\nimport PIL\nimport pydegensac\nfrom scipy import spatial\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport tensorflow.keras.layers as L\n\nimport subprocess\nsubprocess.call(['pip', 'install', '../input/landmark-ckp/faixx/faiss_gpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl'])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-17T02:58:09.486094Z","iopub.status.busy":"2020-09-17T02:58:09.485266Z","iopub.status.idle":"2020-09-17T02:58:10.25338Z","shell.execute_reply":"2020-09-17T02:58:10.252302Z"},"papermill":{"duration":0.779256,"end_time":"2020-09-17T02:58:10.253502","exception":false,"start_time":"2020-09-17T02:58:09.474246","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import faiss\nimport sys\npackage_path = '../input/efficientnet100minimal/'\npackage_path2 = '../input/keras-applications/'\nsys.path.append(package_path)\nsys.path.append(package_path2)\nimport keras_applications\nimport efficientnet.tfkeras as efn ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-17T02:58:10.27532Z","iopub.status.busy":"2020-09-17T02:58:10.273626Z","iopub.status.idle":"2020-09-17T02:58:15.803829Z","shell.execute_reply":"2020-09-17T02:58:15.803317Z"},"papermill":{"duration":5.54409,"end_time":"2020-09-17T02:58:15.80398","exception":false,"start_time":"2020-09-17T02:58:10.25989","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"INPUT_DIR = os.path.join('..', 'input')\n\nDATASET_DIR = os.path.join(INPUT_DIR, 'landmark-recognition-2020')\nTEST_IMAGE_DIR = os.path.join(DATASET_DIR, 'test')\nTRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train')\nTRAIN_LABELMAP_PATH = os.path.join(DATASET_DIR, 'train.csv')\n\nNUM_PUBLIC_TRAIN_IMAGES = 1580470\nMAX_NUM_EMBEDDINGS = -1\n\nNUM_TO_RERANK = 4\nTOP_K = 3\n\nMAX_INLIER_SCORE = 30\nMAX_REPROJECTION_ERROR = 4.0\nMAX_RANSAC_ITERATIONS = 1000\nHOMOGRAPHY_CONFIDENCE = 0.99\n\nSAVED_MODEL_DIR = '../input/delg-saved-models/local_and_global'\nDELG_MODEL = tf.saved_model.load(SAVED_MODEL_DIR)\nDELG_IMAGE_SCALES_TENSOR = tf.convert_to_tensor([0.70710677, 1.0, 1.4142135])\nDELG_SCORE_THRESHOLD_TENSOR = tf.constant(175.)\nDELG_INPUT_TENSOR_NAMES = [\n    'input_image:0', 'input_scales:0', 'input_abs_thres:0'\n]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-17T02:58:15.824951Z","iopub.status.busy":"2020-09-17T02:58:15.823295Z","iopub.status.idle":"2020-09-17T02:58:56.2423Z","shell.execute_reply":"2020-09-17T02:58:56.241582Z"},"papermill":{"duration":40.431826,"end_time":"2020-09-17T02:58:56.242441","exception":false,"start_time":"2020-09-17T02:58:15.810615","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"NUM_EMBEDDING_DIMENSIONS = 2048\nGLOBAL_FEATURE_EXTRACTION_FN = tf.saved_model.load('../input/google-landmark-subs')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-17T02:58:56.285752Z","iopub.status.busy":"2020-09-17T02:58:56.274608Z","iopub.status.idle":"2020-09-17T02:59:10.041726Z","shell.execute_reply":"2020-09-17T02:59:10.040877Z"},"papermill":{"duration":13.792556,"end_time":"2020-09-17T02:59:10.041903","exception":false,"start_time":"2020-09-17T02:58:56.249347","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"LOCAL_FEATURE_NUM_TENSOR = tf.constant(1000)\nLOCAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(\n    DELG_INPUT_TENSOR_NAMES + ['input_max_feature_num:0'],\n    ['boxes:0', 'features:0'])\n\nLANDMARK_CLS = tf.keras.models.load_model('../input/landmark-ckp/efnb2_cls_/efnb2_v2.h5')\n\ndef to_hex(image_id) -> str:\n  return '{0:0{1}x}'.format(image_id, 16)\n\n\ndef get_image_path(subset, image_id):\n  name = to_hex(image_id)\n  return os.path.join(DATASET_DIR, subset, name[0], name[1], name[2],\n                      '{}.jpg'.format(name))\n\n\ndef load_image_tensor(image_path):\n  return tf.convert_to_tensor(\n      np.array(PIL.Image.open(image_path).convert('RGB')))\n\n\ndef extract_global_features(image_root_dir, n_splits = None, split = None):\n\n  if n_splits:\n    \n      image_paths = [x for x in pathlib.Path(image_root_dir).rglob('*.jpg')]\n    \n      num_images = len(image_paths)\n      split_size = len(image_paths) // n_splits  \n      start = split - 1\n      end = split\n    \n      image_paths = image_paths[(start * split_size): min(end * split_size, len(image_paths))]\n    \n  else:\n\n      image_paths = [x for x in pathlib.Path(image_root_dir).rglob('*.jpg')]\n\n  num_embeddings = len(image_paths)\n  if MAX_NUM_EMBEDDINGS > 0:\n    num_embeddings = min(MAX_NUM_EMBEDDINGS, num_embeddings)\n\n  ids = num_embeddings * [None]\n  embeddings = np.empty((num_embeddings, NUM_EMBEDDING_DIMENSIONS))\n\n  for i, image_path in tqdm(enumerate(image_paths)):\n    if i >= num_embeddings:\n        break\n\n    ids[i] = int(image_path.name.split('.')[0], 16)\n\n    image_tensor = load_image_tensor(image_path)\n\n    embedding_tensor = GLOBAL_FEATURE_EXTRACTION_FN.call(image_tensor)['global_descriptor']\n    embeddings[i, :] = embedding_tensor.numpy()\n    \n  return ids, embeddings\n\n\ndef extract_local_features(image_path):\n\n  image_tensor = load_image_tensor(image_path)\n\n  features = LOCAL_FEATURE_EXTRACTION_FN(image_tensor, DELG_IMAGE_SCALES_TENSOR,\n                                         DELG_SCORE_THRESHOLD_TENSOR,\n                                         LOCAL_FEATURE_NUM_TENSOR)\n\n\n  keypoints = tf.divide(\n      tf.add(\n          tf.gather(features[0], [0, 1], axis=1),\n          tf.gather(features[0], [2, 3], axis=1)), 2.0).numpy()\n\n  descriptors = tf.nn.l2_normalize(\n      features[1], axis=1, name='l2_normalization').numpy()\n\n  return keypoints, descriptors\n\n\ndef get_putative_matching_keypoints(test_keypoints,\n                                    test_descriptors,\n                                    train_keypoints,\n                                    train_descriptors,\n                                    max_distance=0.9):\n\n  train_descriptor_tree = spatial.cKDTree(train_descriptors)\n  _, matches = train_descriptor_tree.query(\n      test_descriptors, distance_upper_bound=max_distance)\n\n  test_kp_count = test_keypoints.shape[0]\n  train_kp_count = train_keypoints.shape[0]\n\n  test_matching_keypoints = np.array([\n      test_keypoints[i,]\n      for i in range(test_kp_count)\n      if matches[i] != train_kp_count\n  ])\n  train_matching_keypoints = np.array([\n      train_keypoints[matches[i],]\n      for i in range(test_kp_count)\n      if matches[i] != train_kp_count\n  ])\n\n  return test_matching_keypoints, train_matching_keypoints\n\n\ndef get_num_inliers(test_keypoints, test_descriptors, train_keypoints,\n                    train_descriptors):\n\n  test_match_kp, train_match_kp = get_putative_matching_keypoints(\n      test_keypoints, test_descriptors, train_keypoints, train_descriptors)\n\n  if test_match_kp.shape[\n      0] <= 4:  \n    return 0\n\n  try:\n    _, mask = pydegensac.findHomography(test_match_kp, train_match_kp,\n                                        MAX_REPROJECTION_ERROR,\n                                        HOMOGRAPHY_CONFIDENCE,\n                                        MAX_RANSAC_ITERATIONS)\n  except np.linalg.LinAlgError:  \n    return 0\n\n  return int(copy.deepcopy(mask).astype(np.float32).sum())\n\n\ndef get_total_score(num_inliers, global_score):\n  local_score = min(num_inliers, MAX_INLIER_SCORE) / MAX_INLIER_SCORE\n  return local_score + global_score\n\n\ndef rescore_and_rerank_by_num_inliers(test_image_id,\n                                      train_ids_labels_and_scores):\n\n  test_image_path = get_image_path('test', test_image_id)\n  test_keypoints, test_descriptors = extract_local_features(test_image_path)\n\n  for i in range(len(train_ids_labels_and_scores)):\n    train_image_id, label, global_score = train_ids_labels_and_scores[i]\n\n    train_image_path = get_image_path('train', train_image_id)\n    train_keypoints, train_descriptors = extract_local_features(\n        train_image_path)\n\n    num_inliers = get_num_inliers(test_keypoints, test_descriptors,\n                                  train_keypoints, train_descriptors)\n    total_score = get_total_score(num_inliers, global_score)\n    train_ids_labels_and_scores[i] = (train_image_id, label, total_score)\n\n  train_ids_labels_and_scores.sort(key=lambda x: x[2], reverse=True)\n\n  return train_ids_labels_and_scores\n\n\ndef load_labelmap():\n  with open(TRAIN_LABELMAP_PATH, mode='r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n    labelmap = {row['id']: row['landmark_id'] for row in csv_reader}\n\n  return labelmap\n\n\ndef get_prediction_map(test_ids, train_ids_labels_and_scores):\n\n  prediction_map = dict()\n\n  for test_index, test_id in enumerate(test_ids):\n    hex_test_id = to_hex(test_id)\n\n    aggregate_scores = {}\n    for _, label, score in train_ids_labels_and_scores[test_index][:TOP_K]:\n      if label not in aggregate_scores:\n        aggregate_scores[label] = 0\n      aggregate_scores[label] += score\n\n    label, score = max(aggregate_scores.items(), key=operator.itemgetter(1))\n\n    prediction_map[hex_test_id] = {'score': score, 'class': label}\n\n  return prediction_map\n\n\ndef decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n    \n    \ndef landmark_cls_score(image_root_dir):\n    image_paths = [x for x in pathlib.Path(image_root_dir).rglob('*.jpg')]\n    image_paths = [os.fspath(x) for x in image_paths]\n    \n    \n    \n    landmark_cls_scores = []\n    ids = []\n    \n    for p in image_paths:\n        tmp = decode_image(p)\n        score = LANDMARK_CLS.predict(tf.expand_dims(tmp, 0))\n        landmark_cls_scores.append(np.float(score))\n        \n        ids.append(p.split('/')[-1].split('.')[0])\n        \n    return dict(zip(ids, landmark_cls_scores))\n\n\ndef get_predictions(labelmap):\n\n  test_ids, test_embeddings = extract_global_features(TEST_IMAGE_DIR)\n\n  print('faiss_1')\n\n  train_ids, train_embeddings = extract_global_features(TRAIN_IMAGE_DIR, n_splits = 2, split = 1)\n\n  train_ids = np.array([to_hex(x) for x in train_ids])\n\n  faiss_index = faiss.IndexFlatIP(NUM_EMBEDDING_DIMENSIONS) \n  faiss_index.add(train_embeddings.astype('float32'))\n  faiss_dist, faiss_index = faiss_index.search(test_embeddings.astype('float32'), NUM_TO_RERANK)\n\n  lookup_ = np.vectorize(lambda x: labelmap[x])\n\n  faiss_labels = lookup_(train_ids[faiss_index])\n\n  combined1 = list(zip([[int(x, 16) for x in y] for y in train_ids[faiss_index].tolist()], \n                     faiss_labels.tolist(), \n                     faiss_dist.tolist()))\n  train_ids_labels_and_scores = [list(zip(x[0], x[1], x[2])) for x in combined1]\n\n  del train_ids\n  del train_embeddings\n  del faiss_index\n  gc.collect()\n\n\n  print('faiss_2')\n\n  train_ids, train_embeddings = extract_global_features(TRAIN_IMAGE_DIR, n_splits = 2, split = 2)\n\n  train_ids = np.array([to_hex(x) for x in train_ids])\n\n  faiss_index = faiss.IndexFlatIP(NUM_EMBEDDING_DIMENSIONS) \n  faiss_index.add(train_embeddings.astype('float32'))\n  faiss_dist, faiss_index = faiss_index.search(test_embeddings.astype('float32'), NUM_TO_RERANK)\n\n  lookup_ = np.vectorize(lambda x: labelmap[x])\n\n  faiss_labels = lookup_(train_ids[faiss_index])\n\n  combined2 = list(zip([[int(x, 16) for x in y] for y in train_ids[faiss_index].tolist()], \n                     faiss_labels.tolist(), \n                     faiss_dist.tolist()))\n\n  train_ids_labels_and_scores2 = [list(zip(x[0], x[1], x[2])) for x in combined2]\n    \n  train_ids_labels_and_scores = [c1 + c2  for c1, c2 in zip(train_ids_labels_and_scores, \n                                                           train_ids_labels_and_scores2)]\n    \n  train_ids_labels_and_scores = [sorted(x, key = lambda x: x[-1])[::-1][:NUM_TO_RERANK] for x in train_ids_labels_and_scores]\n\n  del train_ids\n  del train_embeddings\n  del faiss_index\n  gc.collect()\n    \n    \n  pre_verification_predictions = get_prediction_map(\n      test_ids, train_ids_labels_and_scores)\n\n  for test_index, test_id in enumerate(test_ids):\n    train_ids_labels_and_scores[test_index] = rescore_and_rerank_by_num_inliers(\n        test_id, train_ids_labels_and_scores[test_index])\n\n  post_verification_predictions = get_prediction_map(\n      test_ids, train_ids_labels_and_scores)\n\n  reg_cls_scores = landmark_cls_score(TEST_IMAGE_DIR)\n  score = np.array([v for k, v in reg_cls_scores.items()])\n    \n  curr_avg = 0\n\n  for threshold in [0.1, 0.01, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001, 0.0000005, 0.0000001][::-1]:\n    \n    curr_avg = np.mean(score < threshold)\n    \n    if curr_avg > 0.2:\n        break\n        \n\n  for id_ in post_verification_predictions.keys():\n    \n    cls_score = reg_cls_scores[id_]\n    \n    if cls_score < threshold:\n        post_verification_predictions[id_]['score'] = post_verification_predictions[id_]['score'] * cls_score\n        \n        \n  from collections import Counter\n  pred_classes = [v['class'] for k, v in post_verification_predictions.items()]\n  pred_classes_counts = Counter(pred_classes)\n  filtered_counts = Counter(el for el in pred_classes_counts.elements() if pred_classes_counts[el] >= 30)\n\n  omit_ks = [k for k in filtered_counts]\n\n\n  for id_ in post_verification_predictions.keys():\n\n    lbl = post_verification_predictions[id_]['class']\n\n    if lbl in omit_ks:\n        post_verification_predictions[id_]['score'] = post_verification_predictions[id_]['score'] * -1\n        \n      \n  return pre_verification_predictions, post_verification_predictions\n\n\n\ndef save_submission_csv(predictions=None):\n\n  if predictions is None:\n\n    shutil.copyfile(\n        os.path.join(DATASET_DIR, 'sample_submission.csv'), 'submission.csv')\n    return\n\n  with open('submission.csv', 'w') as submission_csv:\n    csv_writer = csv.DictWriter(submission_csv, fieldnames=['id', 'landmarks'])\n    csv_writer.writeheader()\n    for image_id, prediction in predictions.items():\n      label = prediction['class']\n      score = prediction['score']\n      csv_writer.writerow({'id': image_id, 'landmarks': f'{label} {score}'})\n\ndef main():\n  labelmap = load_labelmap()\n  num_training_images = len(labelmap.keys())\n  print(f'Found {num_training_images} training images.')\n\n  if num_training_images == NUM_PUBLIC_TRAIN_IMAGES:\n    print('Found NUM_PUBLIC_TRAIN_IMAGES. Copying sample submission.')\n    save_submission_csv()\n    return\n\n  _, post_verification_predictions = get_predictions(labelmap)\n  save_submission_csv(post_verification_predictions)\n\n\nif __name__ == '__main__':\n  main()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":0.006755,"end_time":"2020-09-17T02:59:10.056081","exception":false,"start_time":"2020-09-17T02:59:10.049326","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(\"done!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}